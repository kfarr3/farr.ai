Title: Intro to Inferential Statistics
Date: 2017-12-18 08:50
Author: i6hb4k
Category: Uncategorized
Slug: 251
Status: draft

I just finished another course offered for free by the great people at udacity.com, [Intro to Inferential Statistics](https://www.udacity.com/course/intro-to-inferential-statistics--ud201).  This was a definite step in the right direction after taking the Intro to Description Statistics class that I talk about [here](https://kennethfarr.com/intro-to-descriptive-statistics/).   Inferential statistics help you find approximate answers to problems, make predictions, and verify the accuracy of the models.

The real work starts in Lesson 2, Estimation, since Lesson 1 was review of Descriptive Statistics.  Here we learn about Margin of Error, something most people have a concept of, but calculating it accurately is imperative to presenting good statistics.  The lesson also covered Confidence Level, where one can say with confidence that a percentage of the true population falls within a specified range of the sample, and Confidence Interval where we expect the upper and lower bound of our population mean.  Also introduced was the Critical Z-Score, which is used to define our critical region for our confidence interval.

Hypothesis Testing is Lesson 3.  This was touched on in Descriptive Statistics, but more thoroughly explored in this lesson.  Again, concepts such as Alpha Level, used to determine the critical region are explained and the usage of Z-Tables to determine the values.  There's also more explanation of the Null Hypothesis, the claim we are trying to prove against, and the Alternative Hypothesis, the result we are checking the claim against.  Accuracy is categorized as either Type I or Type II errors.  Where a Type I error is when you reject the NULL when the NULL is true, also known as a False Positive.  While a Type II error is when you accept the NULL when the NULL is false, also known as a True Negative.  Depending on your test, a larger Type I or Type II error is allowed, often they are mutually exclusive, increasing one lowers the other.

Lesson 4 and 5 cover t-Tests, which is used when we do not know the population standard deviation, unlike a z-test, which is what we use when we do.  The t-statistic is used much like the z-statistic, with critical regions defined in a t-table.  In addition Cohen's d is a statistic that measures the effect size of a trial.  It gives us the distance between the means in standardized units.  Much like before, this lesson covers Confidence Intervals and Margin of Error in regards to using the t-stat.
